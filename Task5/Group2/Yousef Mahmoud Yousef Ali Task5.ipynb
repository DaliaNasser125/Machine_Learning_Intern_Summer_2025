{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81959da7",
   "metadata": {},
   "source": [
    "Importing the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a611154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import missingno as msno\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score , mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216f4a32",
   "metadata": {},
   "source": [
    "Preparing the dataset & printing basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cf0183d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (500000, 26)\n",
      "\n",
      "\n",
      "First rows:\n",
      "     User ID          User Name       Driver Name Car Condition Weather  \\\n",
      "0  KHVrEVlD     Kimberly Adams        Amy Butler     Very Good   windy   \n",
      "1  lPxIuEri       Justin Tapia  Hannah Zimmerman     Excellent  cloudy   \n",
      "2  gsVN8JLS    Elizabeth Lopez    Amanda Jackson           Bad  stormy   \n",
      "3  9I7kWFgd      Steven Wilson          Amy Horn     Very Good  stormy   \n",
      "4  8QN5ZaGN  Alexander Andrews  Cassandra Larson           Bad  stormy   \n",
      "\n",
      "   Traffic Condition                            key  fare_amount  \\\n",
      "0  Congested Traffic    2009-06-15 17:26:21.0000001          4.5   \n",
      "1       Flow Traffic    2010-01-05 16:52:16.0000002         16.9   \n",
      "2  Congested Traffic   2011-08-18 00:35:00.00000049          5.7   \n",
      "3       Flow Traffic    2012-04-21 04:30:42.0000001          7.7   \n",
      "4  Congested Traffic  2010-03-09 07:51:00.000000135          5.3   \n",
      "\n",
      "       pickup_datetime  pickup_longitude  ...  month  weekday  year  \\\n",
      "0  2009-06-15 17:26:21         -1.288826  ...      6        0  2009   \n",
      "1  2010-01-05 16:52:16         -1.291824  ...      1        1  2010   \n",
      "2  2011-08-18 00:35:00         -1.291242  ...      8        3  2011   \n",
      "3  2012-04-21 04:30:42         -1.291319  ...      4        5  2012   \n",
      "4  2010-03-09 07:51:00         -1.290987  ...      3        1  2010   \n",
      "\n",
      "    jfk_dist   ewr_dist   lga_dist   sol_dist   nyc_dist  distance   bearing  \n",
      "0  20.265840  55.176046  14.342611  34.543548  27.572573  1.030764 -2.918897  \n",
      "1  44.667679  31.832358  23.130775  15.125872   8.755732  8.450134 -0.375217  \n",
      "2  43.597686  33.712082  19.865289  17.722624   9.847344  1.389525  2.599961  \n",
      "3  42.642965  32.556289  21.063132  15.738963   7.703421  2.799270  0.133905  \n",
      "4  43.329953  39.406828  15.219339  23.732406  15.600745  1.999157 -0.502703  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "\n",
      "\n",
      "Data types:\n",
      " User ID               object\n",
      "User Name             object\n",
      "Driver Name           object\n",
      "Car Condition         object\n",
      "Weather               object\n",
      "Traffic Condition     object\n",
      "key                   object\n",
      "fare_amount          float64\n",
      "pickup_datetime       object\n",
      "pickup_longitude     float64\n",
      "pickup_latitude      float64\n",
      "dropoff_longitude    float64\n",
      "dropoff_latitude     float64\n",
      "passenger_count        int64\n",
      "hour                   int64\n",
      "day                    int64\n",
      "month                  int64\n",
      "weekday                int64\n",
      "year                   int64\n",
      "jfk_dist             float64\n",
      "ewr_dist             float64\n",
      "lga_dist             float64\n",
      "sol_dist             float64\n",
      "nyc_dist             float64\n",
      "distance             float64\n",
      "bearing              float64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Duplicated rows:\n",
      " 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_file = pd.read_csv(\"final_internship_data.csv\")\n",
    "print(\"Shape: \", data_file.shape); print(\"\\n\")\n",
    "print(\"First rows:\\n\", data_file.head()); print(\"\\n\")\n",
    "print(\"Data types:\\n\", data_file.dtypes); print(\"\\n\")\n",
    "print(\"Duplicated rows:\\n\", data_file.duplicated().sum()); print(\"\\n\")\n",
    "\n",
    "data_file.columns = [col.strip().lower().replace(\" \", \"_\") for col in data_file.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747dba0a",
   "metadata": {},
   "source": [
    "Checking for any missing or duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "32cc05be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values (%):\n",
      " user_id              0.000\n",
      "user_name            0.000\n",
      "driver_name          0.000\n",
      "car_condition        0.000\n",
      "weather              0.000\n",
      "traffic_condition    0.000\n",
      "key                  0.000\n",
      "fare_amount          0.000\n",
      "pickup_datetime      0.000\n",
      "pickup_longitude     0.000\n",
      "pickup_latitude      0.000\n",
      "dropoff_longitude    0.001\n",
      "dropoff_latitude     0.001\n",
      "passenger_count      0.000\n",
      "hour                 0.000\n",
      "day                  0.000\n",
      "month                0.000\n",
      "weekday              0.000\n",
      "year                 0.000\n",
      "jfk_dist             0.001\n",
      "ewr_dist             0.001\n",
      "lga_dist             0.001\n",
      "sol_dist             0.001\n",
      "nyc_dist             0.001\n",
      "distance             0.001\n",
      "bearing              0.001\n",
      "dtype: float64\n",
      "The remaining columns:  ['user_id', 'user_name', 'driver_name', 'car_condition', 'weather', 'traffic_condition', 'key', 'fare_amount', 'pickup_datetime', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'passenger_count', 'hour', 'day', 'month', 'weekday', 'year', 'jfk_dist', 'ewr_dist', 'lga_dist', 'sol_dist', 'nyc_dist', 'distance', 'bearing']\n"
     ]
    }
   ],
   "source": [
    "#checking for missing values\n",
    "missing_part = data_file.isnull().mean() * 100\n",
    "print(\"Missing values (%):\\n\", missing_part)\n",
    "\n",
    "#dropping duplicates\n",
    "data_file.drop_duplicates(inplace=True)\n",
    "print(\"The remaining columns: \", data_file.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6911950b",
   "metadata": {},
   "source": [
    "Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4cd08c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fature Engineering - datetime features\n",
    "if 'pickup_datetime' in data_file.columns:\n",
    "    data_file['pickup_datetime'] = pd.to_datetime(data_file['pickup_datetime'])\n",
    "    data_file['hour'] = data_file['pickup_datetime'].dt.hour\n",
    "    data_file['day'] = data_file['pickup_datetime'].dt.day\n",
    "    data_file['month'] = data_file['pickup_datetime'].dt.month\n",
    "    data_file['weekday'] = data_file['pickup_datetime'].dt.weekday\n",
    "    data_file['year'] = data_file['pickup_datetime'].dt.year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348c1fb6",
   "metadata": {},
   "source": [
    "Creating some new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1743ed8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 = saturday, 6 = sunday\n",
    "data_file['is_weekend'] = data_file['weekday'].isin([5,6])\n",
    "\n",
    "#mornings and evenings\n",
    "data_file['rsuh_hours'] = data_file['hour'].between(7 , 10) | data_file['hour'].between(16,19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c91fe5",
   "metadata": {},
   "source": [
    "Data cleansing Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dd32a99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fare_amount: 0 outliers have been removed\n",
      "pickup_longitude: 456669 outliers have been removed\n",
      "pickup_latitude: 439229 outliers have been removed\n",
      "dropoff_longitude: 432451 outliers have been removed\n",
      "dropoff_latitude: 424984 outliers have been removed\n",
      "passenger_count: 0 outliers have been removed\n",
      "jfk_dist: 0 outliers have been removed\n",
      "ewr_dist: 0 outliers have been removed\n",
      "lga_dist: 0 outliers have been removed\n",
      "sol_dist: 0 outliers have been removed\n",
      "nyc_dist: 0 outliers have been removed\n",
      "distance: 0 outliers have been removed\n",
      "bearing: 0 outliers have been removed\n"
     ]
    }
   ],
   "source": [
    "#--> filling the numerical missing values with median method\n",
    "numer_col = data_file.select_dtypes(include=['int64','float64']).columns\n",
    "for column in numer_col:\n",
    "    data_file[column].fillna(data_file[column].median(), inplace=True)\n",
    "\n",
    "#categorical with mode\n",
    "cate_col = data_file.select_dtypes(include='object').columns\n",
    "for col in cate_col:\n",
    "    data_file[col].fillna(data_file[col].mode()[0], inplace= True)\n",
    "\n",
    "#fixing the inconsistent values\n",
    "if 'meal' in data_file.columns:\n",
    "    data_file['meal'] = data_file['meal'].replace('Undefined', 'SC')\n",
    "\n",
    "#handling outliers with IQR\n",
    "\n",
    "def IQR_Function(data_file, columns):\n",
    "    for col in columns:\n",
    "        Quart_1 = data_file[col].quantile(0.25)\n",
    "        Quart_3 = data_file[col].quantile(0.75)\n",
    "        IQR = Quart_3 - Quart_1\n",
    "        lower_b = Quart_1 - 1.5 * IQR\n",
    "        upper_b = Quart_3 + 1.5 * IQR\n",
    "        outliers = data_file[(data_file[col] < lower_b) | data_file[col] > upper_b]\n",
    "        print(f\"{col}: {len(outliers)} outliers have been removed\")\n",
    "        data_file = data_file[(data_file[col] >= lower_b) & (data_file[col]<=upper_b)]\n",
    "    return data_file\n",
    "\n",
    "\n",
    "\n",
    "data_file = IQR_Function(data_file, numer_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f9dd69",
   "metadata": {},
   "source": [
    "Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "756a47a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "LE_Cols = ['user_id', 'user_name', 'driver_name']\n",
    "LE = LabelEncoder()\n",
    "for col in LE_Cols:\n",
    "    data_file[col] = LE.fit_transform(data_file[col])\n",
    "\n",
    "\n",
    "OH_Cols = ['car_condition', 'weather', 'traffic_condition']\n",
    "data_file = pd.get_dummies(data_file, columns=OH_Cols, drop_first=True)\n",
    "\n",
    "#non-useful columns\n",
    "data_file.drop(['pickup_datetime', 'key'], axis=1, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ac7aee",
   "metadata": {},
   "source": [
    "Linear Regression Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08847ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 1.46\n",
      "Approximated Accuracy = 82.36%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "X = data_file.drop(columns=['fare_amount'])\n",
    "Y = data_file['fare_amount']\n",
    "\n",
    "X_train, X_test, Y_train, Y_Test = train_test_split(X , Y, test_size=0.4, random_state=30)\n",
    "\n",
    "linearRegression = LinearRegression()\n",
    "linearRegression.fit(X_train, Y_train)\n",
    "predict = linearRegression.predict(X_test)\n",
    "\n",
    "MAE = mean_absolute_error(Y_Test , predict)\n",
    "acc_lin = 100 * (1 - (MAE / Y.mean()))\n",
    "print(f\"MAE = {MAE:.2f}\")\n",
    "print(f\"Approximated Accuracy = {acc_lin:.2f}%\")\n",
    "#First try: 82.41%, 0.5 , 40\n",
    "#Second try: 82.44%, 0.4 , 40\n",
    "#Third try: 82.25%, 0.1 , 40\n",
    "#Fourth try: 82.36, 0.4, 30\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e142b9b3",
   "metadata": {},
   "source": [
    "RandomForest Algorithm!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceca07a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Sqaured = 0.5578\n",
      "Approximated accuracy = 79.77%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score , mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X = data_file.drop(columns=['fare_amount'])\n",
    "y = data_file['fare_amount']\n",
    "\n",
    "X_train, X_test, Y_train, Y_Test = train_test_split(X , y , test_size = 0.3, random_state = 35)\n",
    "R_Forest = RandomForestRegressor(n_estimators=50, max_depth= 2 , random_state= 40, n_jobs=-1)\n",
    "R_Forest.fit(X_train , Y_train)\n",
    "\n",
    "Results = R_Forest.predict(X_test)\n",
    "\n",
    "\n",
    "R2 = r2_score(Y_Test , Results)\n",
    "MAE = mean_absolute_error(Y_Test , Results)\n",
    "print(f\"R Sqaured = {R2:.4f}\")\n",
    "Accuracy = 100 * (1-(MAE/y.mean()))\n",
    "print(f\"Approximated accuracy = {Accuracy:.2f}%\")\n",
    "#First try: 82.60%, 100 , 5 , 30\n",
    "#Second try: 85.63%, 150 , 15 , 40\n",
    "#Third try: 85.73%, 250 , 20 , 40  \n",
    "#Fourth try: 85.71%, 350 , 40 , 40\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e11257",
   "metadata": {},
   "source": [
    "Linear Regression Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ef9dedd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 1.45\n",
      "Approximated Accuracy = 82.44%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "X = data_file.drop(columns=['fare_amount'])\n",
    "Y = data_file['fare_amount']\n",
    "\n",
    "X_train, X_test, Y_train, Y_Test = train_test_split(X , Y, test_size=0.3, random_state=40)\n",
    "\n",
    "linearRegression = LinearRegression()\n",
    "linearRegression.fit(X_train, Y_train)\n",
    "predict = linearRegression.predict(X_test)\n",
    "\n",
    "MAE = mean_absolute_error(Y_Test , predict)\n",
    "acc_lin = 100 * (1 - (MAE / Y.mean()))\n",
    "print(f\"MAE = {MAE:.2f}\")\n",
    "print(f\"Approximated Accuracy = {acc_lin:.2f}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
